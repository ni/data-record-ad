# Getting Started

The Data Record AD Development Suite installs the IO Plugin Creation Toolkit, which includes a template project and scripting tool.

In LabVIEW Navigate to File->Create Project->ADAS->ADAS IO Plugin Template

In LabVIEW, create a new ADAS IO Plugin:

![image](https://user-images.githubusercontent.com/39499264/121237173-5f848980-c85c-11eb-839c-cae3b9d66b72.png)

Select a name for the IO Plugin and a location where you'd like the files to be generated (the IO Plugin Directory will be different on your system)

![image](https://user-images.githubusercontent.com/39499264/121237211-6a3f1e80-c85c-11eb-9320-62de234f0cec.png)

Click Finish.  LabVIEW will now generate a new project with everything you need for an IO Plugin.
Navigate to the location you chose for the IO Plugin Directory and open the project:

![image](https://user-images.githubusercontent.com/39499264/121237234-71fec300-c85c-11eb-9d27-7e3d6bce3900.png)

Most of the files generated by the template are needed for the plugin to operate, but do not need to be (and should not be) modified.

To find a list of what actions should be taken to customize the plugin, open the Bookmark Manager (View>>Bookmark Manager).

![image](https://user-images.githubusercontent.com/39499264/121237252-77f4a400-c85c-11eb-9c86-ba52f5eda3df.png)

Each of the #TODO bookmarks shows a place within the plugin where you can customize the behavior.

## Functions to Modify

The main parts of the project that you will modify are the VIs in the States folder of the plugin class.  Each plugin defines behavior for the different states that the ADAS engine supports.  

### Configuration

- #### Configuration.ctl
  - ![image](https://user-images.githubusercontent.com/39499264/121237337-9064be80-c85c-11eb-82a4-5f78bfc38ef1.png)

- #### Plugin Class Private Data 
  - (ExamplePlugin.ctl in this example)
  - ![image](https://user-images.githubusercontent.com/39499264/121237359-96f33600-c85c-11eb-9d6c-b4b53109c981.png)
  - Keep the Configuration item in the class private data - this is the type definition you modified in the previous step (Configuration.ctl).  Add whatever other items your plugin needs at run time to the cluster.  For example, if your plugin reads data from a UDP port, you might store the UDP connection reference in addition to the Configuration type def.  If your plugin writes incoming data to a TDMS file, you might store the TDMS file reference.
    - Any new items you add to the class private data should also be exposed via accessor methods and property nodes.  Once you have added the items to the class private data, right-click on the class and select New>>VI for Data Member Access, select the new items, configure for Read and Write access, enable the Make available through Property Nodes option and store them in an Accessors folder.  See screenshot below for an example:
  - ![image](https://user-images.githubusercontent.com/39499264/121237380-9f4b7100-c85c-11eb-806c-7f0c3ab7a1f6.png)

- #### Default Configuration Parameters.vi
  - This function is used to tell the configuration editor what values to use as defaults for the configuration cluster.  It has a constant of the Configuration.ctl typedef modified earlier.  Populate the constant with the correct default values for your plugin.
  - ![image](https://user-images.githubusercontent.com/39499264/121237400-a5415200-c85c-11eb-8b6b-e138b2e0edeb.png)

- ### Initialize
  - This is called once for the entire lifetime of the plugin, and is where the timing option for the plugin is set if the value is not based on the configuration file. 
  - Initialize is called before the plugin loads its configuration
  - Timing options:
    - Periodic: Specify a millisecond period for the Process loop to run at.  Useful for status data sources such as system health that don't get timing from a hardware driver call.  Avoid using this for process or sink PEs, since if the data source produces data more quickly than the data sink runs, a memory growth will occur in the queue linking the plugins.
    - Immediate: Run the process loop as quickly as possible, with no added delay between calls. Use if the Process loop blocks execution on its own, for instance to wait for DAQ samples to be ready.
    - On Data Ready: Run process whenever data arrives on the Input stream. Use for sink or process PEs that process input data that comes from another plugin.  Do not use for data source plugins.  Use this instead of Periodic to avoid memory growth.
    - Triggered: A mode only applicable in FlexLogger - do not use in Data Record AD 
  - Most plugins will use Immediate if they are the source of data or On Data Ready if they are a sink of data.
- ### Read Parameters
  - You do not need to edit this function.  
  - This function loads in the configuration parameters for the plugin (for example, the file path to log to or the CAN interface name to read from)
- ### Configure Session
  - Called once per session, and is always called after the plugin loads its configuration
  - For the ADAS use case, we typically only have a single session of a plugin during a run.  In the future we may add the ability to support multiple sessions.
  - In this VI, take the configuration parameters and call the appropriate initialization functions to open and store any references needed during the run.  For example, call Open/Create/Replace File on the path stored in configuration and store the file reference as part of the class private data for the plugin class.
  - If your plugin needs information from the configuration to decide what timing parameters to use (for example, to configure the period of a Periodic timing), set those here instead of in the Initialize function.
- ### Process
  - This is where the vast majority of the work done by your plugin will happen.  Here, your plugin can read the data that was sent to the plugin (if any), perform some action(s), and optionally send data to the PEF Engine for other plugins to receive.
  - The Process state gets called repeatedly by the engine.  You do not need to implement a while loop to continuously run in the Process state.  Your process state must not call any code with an infinite timeout.  Instead, use a defined timeout and handle/ignore the timeout error accordingly.  This ensures that the system does not hang or get stuck.
  - There may be many instances of the same plugin running on the system.  Because the state VIs in plugins run with Shared Clone reentrancy, there is no guarantee that any data stored in diagram or front panel structures (such as feedback nodes, shift registers, front panel objects, etc) are from the same instance of the plugin.  Any data that needs to persist between calls to the Process VI must be persisted in the class private data of the plugin.
  - If you are making a logging plugin that records raw data sent to the plugin to TDMS, your process function might look something like this:
![image](https://user-images.githubusercontent.com/39499264/121237450-affbe700-c85c-11eb-95d9-b4955bc418d2.png)
     - In this case, you'd use the Read String method (C:\Program Files\National Instruments\LabVIEW 2020\vi.lib\ADAS Record\PEFClasses\Extensions\PEF System Interface\Read String.vi) to get the raw string and write it to the TDMS file reference stored in the class private data.
        - Usually, the data coming in would need to be unflattened to a different data type than string (such as an array of CAN frames) and the timestamp from the Read String function logged as a separate channel in the TDMS file.  This example comes from an early prototype of the TDMS plugin.
     - Since this is purely a data sink, we do not write any data out to the ADAS engine.
   - If you are making a plugin that generates data (such as a UDP reader, or a plugin to get data from a CAN board), often the Process VI will look more like this:
![image](https://user-images.githubusercontent.com/39499264/121237500-bbe7a900-c85c-11eb-835c-760b1e77ddf5.png)
- ### Handle Processing Error
  - This function gets called by the engine if an error occurs in the Process override (if the value of the error out terminal of the Process VI shows an error).  In this function, you can choose what action the engine should take when errors occur.  By default, any error results in the plugin immediately calling its cleanup and finalize states.  You can add a case structure to take different actions for different errors.
  - This function is not present by default in the project generated by the template.  If you want to have different behavior than the default, right click on the States folder in the project and select New VI for override, then select the Handle Processing Error method
  - ![image](https://user-images.githubusercontent.com/39499264/121237572-cdc94c00-c85c-11eb-86c4-8766e0d85169.png)
  - There are three options for the action the plugin should take when an error is detected:
    - Cleanup and Finalize (default): This calls the Cleanup Session and Finalize states of the plugin, after which the plugin is stopped and not running.
    - Cleanup and Configure: This calls the Cleanup Session and then the Configure Session states.  This is equivalent to resetting the plugin and trying to run it again.  The plugin is running and can enter its Process state based on how its timing configuration.
    - Report and Continue: This option reports the error to the debug stream and lets the plugin continue running.  This is equivalent to ignoring the error.
- ### Handle Message
  - This method allows the plugin to register for and take action when certain messages are received (for example, "Start Logging" or "Stop Logging").  By default, plugins just record the message and timestamp to the debug data stream and take no additional action.
  - This method needs additional documentation and examples before it can be easily used.  If you need this, currently you need to ask Systems R & D how to use it.
  - This method runs in a separate thread from the Process VI - any changes made to the class private data of the plugin class will not normally be reflected in the Process VI, since that has a different copy of the class private data.  To communicate changes to the Process VI (for example, to set a flag for 'logging enabled'), wrap the shared data in a DVR and maintain the DVR as part of the class private data.  The DVR should be initialized in the "Initialize" state, modified in the "Configure Session" state if its value depends on the configuration, read in the "Process" state, and destroyed in the "Finalize" state.
- ### Cleanup Session
  - This method is used to close any references opened in Configure Session and flush any buffers used.  
  - This method is followed by either Configure Session (if the plugin is restarting) or Finalize (if the plugin is shutting down)
- ### Finalize
  - This method is called as the plugin is shut down.  If there are any short-duration post-processing actions (such as writing a summary/index file of data just recorded by the plugin) or lifetime references (like DVRs of shared data used with the Handle Message method), take care of those here.

## Deployment
//todo: deployment best practices
  
# Design and Style
  
## Recommendations
	- PEs should be as small as possible but no smaller
	- Rather than targeting single responsibility per PE, consider single use case
	- Multiple PEs that only differ in slight ways are superior to one PE that has a very complex set of configuration parameters
	- PEs should have behavior that is easily testable, even if those tests require real hardware
	- PEs with highly specific logging requirements should handle logging within the PE
	- PEs using reference data (such as IMAQ Image References) should pre-allocate a reasonably-sized ring buffer and reuse reference locations

# IO Plugin Architecture

## Plugin State Machine

Each plugin defines behaviors for various states that the plugin will transition through during system execution.

The underlying engine used for the Data Record AD software (known as the Processing Element Framework, or PEF), controls the state machine of the plugins.  It is responsible for calling the correct state VI of the plugins at the appropriate times, as well as for loading and unloading the plugins based on the configuration file.  

Any information that needs to be retained between calls to the state VIs (such as file references, driver session references, counters, etc) need to be stored in the class private data of the plugin.  PEF will manage passing the class private data of a plugin to each call of the plugin's state VIs.  Do not store any data in uninitialized shift registers or feedback nodes or the front panel.  Any data to be retained between calls (even to the same state, such as Process) must be stored in the class private data cluster to work.

Because datalogger plugins extend the Processing Element Framework, they are sometimes referred to as PEs (Processing Elements).

To simplify the creation of datalogger plugins, a project template is provided that defines all necessary functions.  A plugin developer will need to modify the functions generated by the template to give the new plugin the desired behavior.

![image](https://user-images.githubusercontent.com/39499264/121237283-804cdf00-c85c-11eb-97bf-1cc7a10aad57.png)

# Plugin Design Configurations and Constraints

## Interop with the System Configuration Utility

Since Data Record AD does not support editing configurations live, the Configurator must expose all the parameters required to launch the plugin and have it work. As such, as few parameters as possible should be exposed to the customer, especially if some parameters can be derived from / depend on other parameters. At the time of this writing, any illegal configurations or configurations that will fail at runtime cannot be caught by the configurator, and this significantly slows down the development process, and can be difficult to debug. 

Avoid magic strings, doubles, and heavily nested clusters. If possible, give your parameters descriptive names to influence what the customer is supposed to do. Avoid arrays when possible as this is difficult to navigate for a user.

## High-speed vs Low-speed logging

PEF passes data between PEs using very performant flattening and enqueues/dequeues to the PEF data store via the System Interface API. In generic logging use cases, as in FlexLogger, PEs should be written as small as possible, their sole responsibility to generate data to place onto the System Interface, to be passed through the Logging Gate and consumed by the TDMS plugin. Since the logging interface is clearly defined, data generation PEs can be small and are loosely coupled.

In the Data Record AD use case, not all data types have the same constraints: 

	- Data Record AD will support multiple logging formats in addition to TDMS, such as MD4 
	- For example, a PE pulling CAN frames generally does so at low-enough speeds and bandwidth that there is no issue passing through the System Interface, and the datatype is clearly defined such that it can cleanly be supported by FlexLogger's TDMS PE, or any decoupled logging PE with no performance drawbacks.
	- A high-speed camera, whether IMAQ or FPGA, generates data incredibly quickly, and entire flattened images are much too large to be sent via System Interface at the required speeds. Therefore, it is only feasible to pass Image References across PEs and have the consumer retrieve the image for immediate consumption (publishing to a UI topic or logging).
		○ This can be complex because images can come in a variety of shapes, sizes, bit depths, etc. which can make it difficult or unwieldy for a consumer PE to handle all cases.
		○ Concurrent access to the same image reference across multiple consumers can cause race conditions if the producer is still writing images and reusing references. References need to be released but not before all consumers have used them. This is difficult to genericize. 
		○ Some logging speeds/use cases can only be achieved using incredibly performant schemes like TDMS Advanced Asynchronous Write, which directly operates on EDVRs instead of forcing the user to open the image reference inline.

## Generic vs. Specific

If sections of your plugin or specific subfunctions can have high reuse potential, consider making them a separate library in your repo, and calling that library within your code. Not all useful code has to be a plugin. For example, logging code (such as MDF4) might be more appropriate as a reuse library that a PE developer uses like a palette, rather than a standalone plugin.

## Code duplication vs. Abstraction

Think of the customer, not the developer. In general, highly abstract PEs require the customer to jump through more hoops at configuration-time in order for the PE to do what it needs to do. Highly specific PEs are easier to understand for the user and can have descriptive names (NI 1487 GMSL 8-channel with Logging vs NI 1487 GMS 4-channel no Logging). This will not be hard to see on a configurator palette. 

## Monoliths vs. Distribution

If 2 plugins only work when they're together, make them one plugin.
If a plugin only works with another plugin when multiple parameters match in a specific way, consider one plugin.

## Reducing Customer Error Opportunity

Don't count on error handling to descriptively tell your customers exactly where a configuration went wrong. Make it easy and intuitive to understand.

# New Features

## TestSystemInterface
  
The TestSystemInterface library can be found in `<vi.lib>/FlexLogger/TestSystemInterface` **(Data Record AD 1.1 and later only)**

Single PE example (in the PE's project)
![image](https://user-images.githubusercontent.com/39499264/127672188-3e330d7f-5d82-4a20-88f8-e7bb9f0215b3.png)

Multi-PE example (in some Integration Tests project that has source for both PEs)
![image](https://user-images.githubusercontent.com/39499264/127672248-1d777d6b-0bf6-4256-bbd5-e9b8793f54e6.png)

## DataStreamGrpc Messaging

Whenever using a new DataStreamGrpc Server or client in a plugin, please ensure you have included `<vi.lib>/DataStreamGrpc/External/zlib.dll` in your LabVIEW project, and marked it as an Always Include in the LabVIEW Build Specification for your PPL. This DLL is a compression library required as a dependency for gRPC, but is not called directly anywhere in the DataStreamGrpc LabVIEW API, so LabVIEW does not know to copy it when building the PPL. If you skip this step, you will see **Error 1498** from the build PPL on its first gRPC call.
